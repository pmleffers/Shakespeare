{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from  future import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM,Activation,Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Project Gutenberg eBook of the complete works of William Shakespeare’s dataset is used to train the network for automated text generation. Data can be downloaded from http:// www.gutenberg.org/ for the raw file used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.gutenberg.org/\n",
    "#http://www.gutenberg.org/files/100/100-0.txt\n",
    "#https://hub.packtpub.com/auto-generate-texts-shakespeare-writing-using-deep-recurrent-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to create a dictionary of characters to indices and vice-versa mapping, which we will be using to convert text into indices at later stages. This is because deep learning models cannot understand English and everything needs to be mapped into indices to train these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/pmlef/Desktop/Python_work/Selenium/Shakespeare.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path, encoding=\"utf8\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 5667137\n",
      "total chars: 72\n"
     ]
    }
   ],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "print('corpus length:', len(text))\n",
    "print('total chars:', len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2indices = dict((c, i) for i, c in enumerate(characters))\n",
    "indices2char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, various preprocessing steps are involved to make it work. The following are the major steps involved:\n",
    "\n",
    "    Preprocessing: Prepare X and Y data from the given entire story text file and converting them into indices vectorized format.\n",
    "    Deep learning model training and validation: Train and validate the deep learning model.\n",
    "    Text generation: Generate the text with the trained model.\n",
    "\n",
    "How it works…\n",
    "\n",
    "The following lines of code describe the entire modeling process of generating text from Shakespeare’s writings. Here we have chosen character length. This needs to be considered as 40 to determine the next best single character, which seems to be very fair to consider. Also, this extraction process jumps by three steps to avoid any overlapping between two consecutive extractions, to create a dataset more fairly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "np_sequence=0\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    np_sequence=len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block is used to convert the data into a vectorized format for feeding into deep learning models, as the models cannot understand anything about text, words, sentences and so on. Initially, total dimensions are created with all zeros in the NumPy array and filled with relevant places with dictionary mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting indices into vectorized format\n",
    "\n",
    "X = np.zeros((len(sentences), maxlen, len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char2indices[char]] = 1\n",
    "        y[i, char2indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep learning model is created with RNN, more specifically Long Short-Term Memory networks with 128 hidden neurons, and the output is in the dimensions of the characters. The number of columns in the array is the number of characters. Finally, the softmax function is used with the RMSprop optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               102912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 72)                9288      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72)                0         \n",
      "=================================================================\n",
      "Total params: 112,200\n",
      "Trainable params: 112,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model Building\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, deep learning models train on number indices to map input to output (given a length of 40 characters, the model will predict the next best character). The following code is used to convert the predicted indices back to the relevant character by determining the maximum index of the character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert prediction into index\n",
    "\n",
    "def pred_indices(preds, metric=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    #if preds.all()==0: preds==10**-10\n",
    "    preds = np.log(preds+10**-10) / metric#\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be trained over 30 iterations with a batch size of 128. And also, the diversity has been changed to see the impact on the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Iteration 0\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1806s 956us/step - loss: 1.6298\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"martino and his wife and daughters;\n",
      "coun\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"martino and his wife and daughters;\n",
      "coun\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"martino and his wife and daughters;\n",
      "coun\"\n",
      "----------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1701s 900us/step - loss: 1.5089\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"ar's lips,\n",
      "    finger of birth-strangled\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"ar's lips,\n",
      "    finger of birth-strangled\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"ar's lips,\n",
      "    finger of birth-strangled\"\n",
      "----------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1873s 992us/step - loss: 1.4944\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"ty;\n",
      "    then be at peace, except ye thir\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"ty;\n",
      "    then be at peace, except ye thir\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"ty;\n",
      "    then be at peace, except ye thir\"\n",
      "----------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1796s 951us/step - loss: 2.0777\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"t strike, thy conscience\n",
      "    is so posse\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"t strike, thy conscience\n",
      "    is so posse\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"t strike, thy conscience\n",
      "    is so posse\"\n",
      "----------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1711s 906us/step - loss: 6.0839\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"] 'edward the fourth, by the grace of go\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"] 'edward the fourth, by the grace of go\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"] 'edward the fourth, by the grace of go\"\n",
      "----------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1720s 910us/step - loss: 5.9389\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \", pucelle, hold thy peace;\n",
      "    if talbot\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \", pucelle, hold thy peace;\n",
      "    if talbot\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \", pucelle, hold thy peace;\n",
      "    if talbot\"\n",
      "----------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1815s 961us/step - loss: 4.7332\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \" tide,\n",
      "being prison’d in her eye, like p\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \" tide,\n",
      "being prison’d in her eye, like p\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \" tide,\n",
      "being prison’d in her eye, like p\"\n",
      "----------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1835s 971us/step - loss: 3.6948\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"emn'd upon the act of fornication\n",
      "    to\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"emn'd upon the act of fornication\n",
      "    to\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"emn'd upon the act of fornication\n",
      "    to\"\n",
      "----------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1676s 887us/step - loss: 3.3884\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"\n",
      "achilles.\n",
      "i shall forestall thee, lord \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"\n",
      "achilles.\n",
      "i shall forestall thee, lord \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"\n",
      "achilles.\n",
      "i shall forestall thee, lord \"\n",
      "----------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1650s 873us/step - loss: 3.3725\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"like a worm i’ th’ bud,\n",
      "feed on her dama\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"like a worm i’ th’ bud,\n",
      "feed on her dama\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"like a worm i’ th’ bud,\n",
      "feed on her dama\"\n",
      "----------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1647s 872us/step - loss: 3.3802\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"ves, shade folly. who is he comes here?\n",
      "\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"ves, shade folly. who is he comes here?\n",
      "\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"ves, shade folly. who is he comes here?\n",
      "\"\n",
      "----------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1645s 871us/step - loss: 3.3764\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"idst presume,\n",
      "    thou hadst not liv'd t\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"idst presume,\n",
      "    thou hadst not liv'd t\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"idst presume,\n",
      "    thou hadst not liv'd t\"\n",
      "----------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1642s 869us/step - loss: 3.3814\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"is day come\n",
      "to blow that furnesse out th\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"is day come\n",
      "to blow that furnesse out th\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"is day come\n",
      "to blow that furnesse out th\"\n",
      "----------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1642s 869us/step - loss: 3.3949\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"ever was prince’s child.  happy what fol\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"ever was prince’s child.  happy what fol\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"ever was prince’s child.  happy what fol\"\n",
      "----------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1646s 871us/step - loss: 3.3897\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"en the blood was cool, have threaten'd\n",
      " \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"en the blood was cool, have threaten'd\n",
      " \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"en the blood was cool, have threaten'd\n",
      " \"\n",
      "----------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1649s 873us/step - loss: 3.4005\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \" it: i cannot eat it.\n",
      "  alcibiades. when\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \" it: i cannot eat it.\n",
      "  alcibiades. when\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \" it: i cannot eat it.\n",
      "  alcibiades. when\"\n",
      "----------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1650s 874us/step - loss: 3.3940\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"dromio of syracuse. no? why, 'tis a plai\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"dromio of syracuse. no? why, 'tis a plai\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"dromio of syracuse. no? why, 'tis a plai\"\n",
      "----------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1649s 873us/step - loss: 3.3976\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"\n",
      "    my soul!                           \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"\n",
      "    my soul!                           \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"\n",
      "    my soul!                           \"\n",
      "----------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1685s 892us/step - loss: 3.4076\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \" found so, master page. master doctor\n",
      "  \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \" found so, master page. master doctor\n",
      "  \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \" found so, master page. master doctor\n",
      "  \"\n",
      "----------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889033/1889033 [==============================] - 1731s 916us/step - loss: 3.4113\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"oubt some noble creature in her,\n",
      "    das\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"oubt some noble creature in her,\n",
      "    das\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"oubt some noble creature in her,\n",
      "    das\"\n",
      "----------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1778s 941us/step - loss: 3.4098\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"ell met, master ford.\n",
      "  ford. trust me, \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"ell met, master ford.\n",
      "  ford. trust me, \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"ell met, master ford.\n",
      "  ford. trust me, \"\n",
      "----------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1718s 909us/step - loss: 3.4044\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"d, and uncle exeter,\n",
      "    we will aboard \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"d, and uncle exeter,\n",
      "    we will aboard \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"d, and uncle exeter,\n",
      "    we will aboard \"\n",
      "----------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1756s 930us/step - loss: 3.4021\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"er mother’s flesh,\n",
      "by the defiling of he\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"er mother’s flesh,\n",
      "by the defiling of he\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"er mother’s flesh,\n",
      "by the defiling of he\"\n",
      "----------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1816s 961us/step - loss: 3.4059\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"ity, your old virginity, is like one of \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"ity, your old virginity, is like one of \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"ity, your old virginity, is like one of \"\n",
      "----------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1731s 916us/step - loss: 3.4051\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"m you\n",
      "have recovered, desire it not. far\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"m you\n",
      "have recovered, desire it not. far\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"m you\n",
      "have recovered, desire it not. far\"\n",
      "----------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1831s 969us/step - loss: 3.4156\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"of it into his face,\n",
      "extinguishing his c\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"of it into his face,\n",
      "extinguishing his c\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"of it into his face,\n",
      "extinguishing his c\"\n",
      "----------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1730s 916us/step - loss: 3.4171\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"nd\n",
      "    as his misdoubts present occasion\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"nd\n",
      "    as his misdoubts present occasion\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"nd\n",
      "    as his misdoubts present occasion\"\n",
      "----------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1641s 868us/step - loss: 3.4181\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"haste you may.\n",
      "                         \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"haste you may.\n",
      "                         \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"haste you may.\n",
      "                         \"\n",
      "----------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1644s 871us/step - loss: 3.4156\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \" be said as lovers they do feign.\n",
      "  audr\"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \" be said as lovers they do feign.\n",
      "  audr\"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \" be said as lovers they do feign.\n",
      "  audr\"\n",
      "----------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/1\n",
      "1889033/1889033 [==============================] - 1640s 868us/step - loss: 3.4200\n",
      "n----- diversity: 0.2\n",
      "----- Generating with seed: \"irits hear me,\n",
      "    and yet i needs must \"\n",
      "n----- diversity: 0.7\n",
      "----- Generating with seed: \"irits hear me,\n",
      "    and yet i needs must \"\n",
      "n----- diversity: 1.2\n",
      "----- Generating with seed: \"irits hear me,\n",
      "    and yet i needs must \"\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model\n",
    "\n",
    "for iteration in range(0, 30):\n",
    "    print('-' * 40)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y,batch_size=128,epochs=1)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    gen_diversity=[]    \n",
    "    for diversity in [0.2, 0.7,1.2]:\n",
    "        print('n----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        gen_diversity.append(generated)\n",
    "        \n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(characters)))\n",
    "\n",
    "        pred_sentence=[]       \n",
    "        pred_chars=[]\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char2indices[char]] = 1.\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = pred_indices(preds, diversity)\n",
    "            pred_char = indices2char[next_index]\n",
    "            generated += pred_char\n",
    "            sentence = sentence[1:] + pred_char\n",
    "            pred_sentence.append(sentence)\n",
    "            pred_chars.append(pred_char)\n",
    "            #sys.stdout.flush()\n",
    "            #print(\"nOne combination completed n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "martino and his wife and daughters; ar's lips, finger of birth-strangled\" \"ty;\n",
    "    then be at peace, except ye thir\" \"t strike, thy conscience\n",
    "    is so posse\" 'edward the fourth, by the grace of go\"  \", pucelle, hold thy peace;\n",
    "    if talbot\" \" tide,\n",
    "being prison’d in her eye, like p\" \"emn'd upon the act of fornication\n",
    "    to\"  \"\n",
    "achilles.\n",
    "i shall forestall thee, lord \"  \"like a worm i’ th’ bud, ves, shade folly. who is he comes here?\n",
    "\"\n",
    "feed on her dama\"  \"idst presume, \"is day come\n",
    "to blow that furnesse out th\"  \"ever was prince’s child.  happy what fol\" en the blood was cool, have threaten'd \" it: i cannot eat it.\n",
    "  alcibiades. when\"  \"dromio of syracuse. no? why, 'tis a plai\"  \"\n",
    "    my soul!                           \" \" found so, master page. master doctor  \"oubt some noble creature in her,\n",
    "    das\"\n",
    "  \" \"ell met, master ford.\n",
    "  ford. trust me, \"  \"d, and uncle exeter,\n",
    "    we will aboard \"  \"er mother’s flesh,\n",
    "by the defiling of he\" \"ity, your old virginity, is like one of \"  \"m you\n",
    "have recovered, desire it not. far\" \"of it into his face,\n",
    "extinguishing his c\"  \"nd\n",
    "    as his misdoubts present occasion\"\n",
    "     \"haste you may.\n",
    "                         \"\" be said as lovers they do feign.\n",
    "  audr\"\"irits hear me,\n",
    "    and yet i needs must \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
